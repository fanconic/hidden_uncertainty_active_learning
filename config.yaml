# Semester Project 2 at ETH
# Hidden Uncertainty for Active Learning
# For further questions contact Claudio Fanconi, fanconic@ethz.ch

name: "baseline_1"

random_state: 42

data:
    dataset: 'mnist'
    batch_size: 32
    nb_classes: 10
    nb_epoch: 1
    data_augmentation: False
    img_rows: 28
    img_cols: 28
    img_channels: 1

model:
    name: "MLP"
    input_height: 28
    input_width: 28
    input_channels: 1
    output_size: 10
    hidden_layers: [128, 128, 128]
    kernel_sizes: [3, 3, 3] # only applied if a (B)CNN is used
    dropout_probabilities: [0.0, 0.5, 0.0]
    use_bias: True


optimizer:
    lr: 0.001
    momentum: 0.9
    weight_decay: 0.0005
    betas: [0.9, 0.999]
